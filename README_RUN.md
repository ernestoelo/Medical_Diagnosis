# Quick Run Instructions

This file contains copy-paste commands for collaborators to get the project running locally.

Prerequisites
- Python 3.9+ (3.11/3.12 tested)
- Git
- Optional: conda or virtualenv for creating isolated environments

Quick start (minimal, copy/paste):

```bash
# 1. Clone the repository (if not done)
git clone https://github.com/ernestoelo/Medical_Diagnosis.git
cd Medical_Diagnosis/Medical_Diagnosis_Assistant

# 2. Create a virtual environment (venv) and activate it
python -m venv .venv
source .venv/bin/activate

# 3. Upgrade pip and install dependencies
pip install --upgrade pip
pip install -r requirements.txt

# NOTE: If you need GPU support, install a torch wheel suitable for your CUDA
# version. See https://pytorch.org for the correct command. The `requirements.txt`
# includes a generic `torch` entry which installs the CPU build by default.

# 4. (Optional) If you will use the Hugging Face API, set your credentials locally
# Do NOT commit this file or values into git.
cat > .env <<'ENV'
# Example .env (DO NOT COMMIT)
# HUGGINGFACE_API_TOKEN=hf_xxx
# HUGGINGFACE_MODEL=d4data/biomedical-ner-all
# USE_LOCAL_ITOE=1
ENV

# 5. Run quick tests
PYTHONPATH=. python tests/test_node_extractor.py

# 6. Run the demo
PYTHONPATH=. python main.py
```

Notes
- The first run will download transformer model weights for NER; this requires internet and may take time.
- The repo contains a local ItôE artifact (`itoe_model.pth` and `itoe_model/`) so inference should work offline for the ItôE part.
- Keep secrets out of git: use `.env` or environment variables. The repository has a `.gitignore` entry for `.env`.

Troubleshooting
- If tests fail because of `torch` import errors, install a compatible PyTorch wheel.
- If inference is slow, use a machine with a GPU or use the Hugging Face hosted API (configure `HUGGINGFACE_API_TOKEN`).

If you want, I can add a small GitHub Action to run these tests on push and prevent secrets from being committed.

---
Generated by the project maintainer assistant.
